{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5649784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from agentfield import AIConfig, Agent\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBAL CONCURRENCY CONTROL\n",
    "# ============================================================================\n",
    "# Global semaphore to limit total concurrent AI calls across all operations\n",
    "MAX_CONCURRENT_CALLS = 20\n",
    "concurrency_semaphore = asyncio.Semaphore(MAX_CONCURRENT_CALLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd99b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "app = Agent(\n",
    "    node_id=\"simulation-engine\",\n",
    "    agentfield_server=f\"{os.getenv('AGENTFIELD_SERVER', 'http://localhost:8080')}\",\n",
    "    ai_config=AIConfig(\n",
    "        model=os.getenv(\"AI_MODEL\", \"openrouter/deepseek/deepseek-v3.1-terminus\"),\n",
    "        api_key=\"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\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69180f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioAnalysis(BaseModel):\n",
    "    \"\"\"Simple schema for scenario decomposition\"\"\"\n",
    "\n",
    "    entity_type: str = Field(\n",
    "        description=\"Type of entity being simulated (e.g., 'customer', 'voter', 'employee')\"\n",
    "    )\n",
    "    decision_type: str = Field(\n",
    "        description=\"Type of decision (e.g., 'binary_choice', 'multi_option', 'continuous_value')\"\n",
    "    )\n",
    "    decision_options: List[str] = Field(\n",
    "        description=\"List of possible decisions/outcomes\"\n",
    "    )\n",
    "    analysis: str = Field(\n",
    "        description=\"Detailed analysis of the scenario including key factors, causal relationships, and what matters\"\n",
    "    )\n",
    "    key_attributes: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"Top 5-7 attributes that matter most for this decision (identified from analysis)\",\n",
    "    )\n",
    "\n",
    "\n",
    "async def decompose_scenario(\n",
    "    scenario: str, context: List[str] = []\n",
    ") -> ScenarioAnalysis:\n",
    "    \"\"\"\n",
    "    Analyzes the scenario to understand what we're simulating.\n",
    "    Returns entity type, decision type, and deep analysis.\n",
    "    \"\"\"\n",
    "    context_str = (\n",
    "        \"\\n\".join([f\"- {c}\" for c in context])\n",
    "        if context\n",
    "        else \"No additional context provided.\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"You are analyzing a simulation scenario to understand what needs to be modeled.\n",
    "\n",
    "SCENARIO:\n",
    "{scenario}\n",
    "\n",
    "CONTEXT:\n",
    "{context_str}\n",
    "\n",
    "TASK:\n",
    "Analyze this scenario deeply and provide:\n",
    "\n",
    "1. entity_type: What type of entity/person are we simulating? (e.g., \"customer\", \"voter\", \"employee\", \"consumer\")\n",
    "\n",
    "2. decision_type: What kind of decision are they making?\n",
    "   - \"binary_choice\" (yes/no, stay/leave)\n",
    "   - \"multi_option\" (choose from several options)\n",
    "   - \"continuous_value\" (a number or amount)\n",
    "\n",
    "3. decision_options: List all possible decisions/outcomes the entity could make. Be specific and exhaustive.\n",
    "\n",
    "4. analysis: Write a comprehensive analysis (3-4 paragraphs) covering:\n",
    "   - What are the key factors that would influence this decision?\n",
    "   - What causal relationships exist? (e.g., \"income affects price sensitivity\")\n",
    "   - What attributes of the entity would matter most?\n",
    "   - What psychological, economic, or social dynamics are at play?\n",
    "   - Are there different segments/archetypes of entities we should consider?\n",
    "   - What hidden variables or second-order effects might exist?\n",
    "\n",
    "Be thorough in your analysis - this will guide the entire simulation.\n",
    "\n",
    "5. key_attributes: Identify the top 5-7 attributes that will MOST influence this decision.\n",
    "   These should be the most predictive factors. Examples: income, price_sensitivity, tenure, loyalty, alternatives.\n",
    "   Return as a list of attribute names (e.g., [\"price_sensitivity\", \"income\", \"tenure\", \"loyalty\", \"alternatives\"]).\"\"\"\n",
    "\n",
    "    async with concurrency_semaphore:  # Global concurrency control\n",
    "        result = await app.ai(prompt, schema=ScenarioAnalysis)\n",
    "\n",
    "    # If key_attributes not provided, use a default set based on common patterns\n",
    "    if not result.key_attributes:\n",
    "        # Default key attributes for common scenarios\n",
    "        if \"price\" in scenario.lower() or \"cost\" in scenario.lower():\n",
    "            result.key_attributes = [\n",
    "                \"price_sensitivity\",\n",
    "                \"income\",\n",
    "                \"budget_constraint\",\n",
    "                \"perceived_value\",\n",
    "                \"alternatives\",\n",
    "            ]\n",
    "        elif \"upgrade\" in scenario.lower() or \"switch\" in scenario.lower():\n",
    "            result.key_attributes = [\n",
    "                \"loyalty\",\n",
    "                \"tenure\",\n",
    "                \"satisfaction\",\n",
    "                \"alternatives\",\n",
    "                \"switching_cost\",\n",
    "            ]\n",
    "        else:\n",
    "            # Generic defaults\n",
    "            result.key_attributes = [\n",
    "                \"loyalty\",\n",
    "                \"satisfaction\",\n",
    "                \"alternatives\",\n",
    "                \"tenure\",\n",
    "                \"value\",\n",
    "            ]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd55409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorGraph(BaseModel):\n",
    "    \"\"\"Schema for the causal attribute graph\"\"\"\n",
    "\n",
    "    attributes: Dict[str, str] = Field(\n",
    "        description=\"Dictionary of attribute_name: description. Each attribute that matters for this entity.\"\n",
    "    )\n",
    "    attribute_graph: str = Field(\n",
    "        description=\"Detailed description of how attributes relate to each other and to the decision, including correlations, dependencies, and causal chains\"\n",
    "    )\n",
    "    sampling_strategy: str = Field(\n",
    "        description=\"Description of how to sample these attributes to get realistic, diverse entities\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def generate_factor_graph(\n",
    "    scenario: str, scenario_analysis: ScenarioAnalysis, context: List[str] = []\n",
    ") -> FactorGraph:\n",
    "    \"\"\"\n",
    "    Creates the factor graph: what attributes matter and how they relate.\n",
    "    \"\"\"\n",
    "    context_str = (\n",
    "        \"\\n\".join([f\"- {c}\" for c in context])\n",
    "        if context\n",
    "        else \"No additional context provided.\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"You are designing the factor graph for a simulation.\n",
    "\n",
    "SCENARIO:\n",
    "{scenario}\n",
    "\n",
    "CONTEXT:\n",
    "{context_str}\n",
    "\n",
    "PREVIOUS ANALYSIS:\n",
    "Entity Type: {scenario_analysis.entity_type}\n",
    "Decision Type: {scenario_analysis.decision_type}\n",
    "Possible Decisions: {', '.join(scenario_analysis.decision_options)}\n",
    "\n",
    "Key Insights from Analysis:\n",
    "{scenario_analysis.analysis}\n",
    "\n",
    "TASK:\n",
    "Design the factor graph that defines what attributes each {scenario_analysis.entity_type} should have.\n",
    "\n",
    "1. attributes: Create a dictionary of all relevant attributes. For each attribute, provide a clear description.\n",
    "   Include attributes across these categories:\n",
    "   - Demographic (age, location, income, etc.)\n",
    "   - Behavioral (usage patterns, preferences, history)\n",
    "   - Psychographic (values, attitudes, personality traits)\n",
    "   - Contextual (external factors, constraints, alternatives available)\n",
    "\n",
    "   Keep attribute names simple and lowercase (e.g., \"age\", \"income_level\", \"price_sensitivity\")\n",
    "   Make descriptions clear and specific.\n",
    "\n",
    "2. attribute_graph: Write a detailed explanation (2-3 paragraphs) of:\n",
    "   - How attributes influence each other (correlations and dependencies)\n",
    "   - How attributes influence the final decision\n",
    "   - What are strong vs weak predictors\n",
    "   - Any interaction effects (e.g., \"age matters more for low-income entities\")\n",
    "   - Which attributes cluster together to form natural segments\n",
    "\n",
    "3. sampling_strategy: Describe how to sample these attributes to create realistic entities:\n",
    "   - What are typical ranges/distributions for each attribute?\n",
    "   - Which attributes are correlated and should be sampled together?\n",
    "   - Are there natural segments/archetypes we should ensure are represented?\n",
    "   - What makes a \"realistic\" vs \"unrealistic\" combination of attributes?\n",
    "\n",
    "Be specific and detailed - this defines the entire simulation space.\"\"\"\n",
    "\n",
    "    async with concurrency_semaphore:  # Global concurrency control\n",
    "        result = await app.ai(prompt, schema=FactorGraph)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73906882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityProfile(BaseModel):\n",
    "    \"\"\"Schema for a single entity's attributes\"\"\"\n",
    "\n",
    "    entity_id: str\n",
    "    attributes: Dict[str, Any] = Field(\n",
    "        description=\"Dictionary of attribute_name: value for this entity\"\n",
    "    )\n",
    "    profile_summary: str = Field(\n",
    "        description=\"2-3 sentence human-readable summary of who this entity is\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EntityBatch(BaseModel):\n",
    "    \"\"\"Schema for generating multiple entities at once\"\"\"\n",
    "\n",
    "    entities: List[Dict[str, Any]] = Field(\n",
    "        description=\"List of entity attribute dictionaries\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c73b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_entity_batch_optimized(\n",
    "    start_id: int,\n",
    "    batch_size: int,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    factor_graph: FactorGraph,\n",
    "    exploration_ratio: float = 0.1,\n",
    ") -> List[EntityProfile]:\n",
    "    \"\"\"\n",
    "    üîß FIXED: Generate multiple entities in ONE AI call to save tokens.\n",
    "    Generate 5-10 entities per call, then parallelize those calls.\n",
    "    \"\"\"\n",
    "    # Generate multiple entities per AI call (but not too many)\n",
    "    entities_per_call = 5  # Sweet spot for quality vs efficiency\n",
    "    num_calls = (batch_size + entities_per_call - 1) // entities_per_call\n",
    "\n",
    "    async def generate_mini_batch(call_num: int) -> List[EntityProfile]:\n",
    "        start = call_num * entities_per_call\n",
    "        count = min(entities_per_call, batch_size - start)\n",
    "\n",
    "        # Determine exploration mode for this mini-batch\n",
    "        exploration_mode = start < int(batch_size * exploration_ratio)\n",
    "\n",
    "        mode_instruction = \"\"\n",
    "        if exploration_mode:\n",
    "            mode_instruction = \"\"\"EXPLORATION MODE: Generate entities with unusual or edge-case attributes.\n",
    "Sample from distribution tails or create surprising but realistic combinations.\"\"\"\n",
    "        else:\n",
    "            mode_instruction = \"\"\"STANDARD MODE: Generate typical, realistic entities following\n",
    "normal distributions and common attribute combinations.\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"Generate {count} synthetic {scenario_analysis.entity_type} entities for simulation.\n",
    "\n",
    "AVAILABLE ATTRIBUTES:\n",
    "{json.dumps(factor_graph.attributes, indent=2)}\n",
    "\n",
    "ATTRIBUTE RELATIONSHIPS:\n",
    "{factor_graph.attribute_graph}\n",
    "\n",
    "SAMPLING GUIDANCE:\n",
    "{factor_graph.sampling_strategy}\n",
    "\n",
    "{mode_instruction}\n",
    "\n",
    "TASK:\n",
    "Generate exactly {count} diverse entities. For each entity, create:\n",
    "- A complete set of attributes (all attributes from the list above)\n",
    "- Values that are realistic and internally consistent\n",
    "- Follow correlations and dependencies described\n",
    "- Ensure diversity across the {count} entities\n",
    "\n",
    "Return a list of {count} dictionaries, where each dictionary contains:\n",
    "- All attribute names as keys\n",
    "- Appropriate values (numbers, strings, booleans as needed)\n",
    "\n",
    "Make entities feel realistic and distinct from each other.\"\"\"\n",
    "\n",
    "        # Use EntityBatch schema to get multiple entities at once\n",
    "        class MiniBatchSchema(BaseModel):\n",
    "            entities: List[Dict[str, Any]] = Field(\n",
    "                description=f\"List of exactly {count} entity attribute dictionaries\"\n",
    "            )\n",
    "\n",
    "        async with concurrency_semaphore:  # Global concurrency control\n",
    "            result = await app.ai(prompt, schema=MiniBatchSchema)\n",
    "\n",
    "        # Convert to EntityProfile objects\n",
    "        profiles = []\n",
    "        for i, entity_attrs in enumerate(result.entities):\n",
    "            entity_id = f\"E_{start_id + start + i:06d}\"\n",
    "\n",
    "            # Generate a quick summary for each entity\n",
    "            attrs_str = \", \".join(\n",
    "                [f\"{k}={v}\" for k, v in list(entity_attrs.items())[:5]]\n",
    "            )\n",
    "            summary = f\"{scenario_analysis.entity_type.title()} with {attrs_str}...\"\n",
    "\n",
    "            profile = EntityProfile(\n",
    "                entity_id=entity_id, attributes=entity_attrs, profile_summary=summary\n",
    "            )\n",
    "            profiles.append(profile)\n",
    "\n",
    "        return profiles\n",
    "\n",
    "    # Parallelize the mini-batch calls\n",
    "    tasks = [generate_mini_batch(i) for i in range(num_calls)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Flatten results\n",
    "    all_entities = []\n",
    "    for batch in results:\n",
    "        all_entities.extend(batch)\n",
    "\n",
    "    return all_entities[:batch_size]  # Trim to exact size\n",
    "\n",
    "\n",
    "# Keep the old function name for backward compatibility\n",
    "async def generate_entity_batch(\n",
    "    start_id: int,\n",
    "    batch_size: int,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    factor_graph: FactorGraph,\n",
    "    exploration_ratio: float = 0.1,\n",
    ") -> List[EntityProfile]:\n",
    "    \"\"\"\n",
    "    Generate a batch of entities (uses optimized batching internally).\n",
    "    \"\"\"\n",
    "    return await generate_entity_batch_optimized(\n",
    "        start_id, batch_size, scenario_analysis, factor_graph, exploration_ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6aad9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDecision(BaseModel):\n",
    "    \"\"\"Schema for entity's decision - simplified to avoid JSON parsing issues\"\"\"\n",
    "\n",
    "    entity_id: str\n",
    "    decision: str = Field(\n",
    "        description=\"The chosen decision/action from the available options\"\n",
    "    )\n",
    "    confidence: float = Field(description=\"Confidence in this decision, 0.0 to 1.0\")\n",
    "    key_factor: str = Field(\n",
    "        description=\"Single most important attribute that influenced this decision (max 50 words)\"\n",
    "    )\n",
    "    trade_off: str = Field(description=\"Main trade-off considered (max 50 words)\")\n",
    "    reasoning: Optional[str] = Field(\n",
    "        default=\"\",\n",
    "        description=\"Brief explanation (1-2 sentences, max 100 words) - optional\",\n",
    "    )\n",
    "\n",
    "\n",
    "async def simulate_entity_decision_safe(\n",
    "    entity: EntityProfile,\n",
    "    scenario: str,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    context: List[str] = [],\n",
    ") -> Optional[EntityDecision]:\n",
    "    \"\"\"\n",
    "    üîß FIXED: Simulates decision with error handling and simplified prompts.\n",
    "    Only shows key attributes (5-7) instead of all attributes to reduce JSON parsing issues.\n",
    "    \"\"\"\n",
    "    async with concurrency_semaphore:  # Global concurrency control\n",
    "        try:\n",
    "            context_str = \"\\n\".join([f\"- {c}\" for c in context]) if context else \"\"\n",
    "\n",
    "            # üîß KEY FIX: Only show top 5-7 key attributes, not all attributes\n",
    "            key_attrs = scenario_analysis.key_attributes[:7]  # Max 7 attributes\n",
    "            if not key_attrs:\n",
    "                # Fallback: use first 5 attributes if key_attributes not set\n",
    "                key_attrs = list(entity.attributes.keys())[:5]\n",
    "\n",
    "            # Build simplified attributes string (only key attributes)\n",
    "            key_attributes_str = \"\\n\".join(\n",
    "                [\n",
    "                    f\"  ‚Ä¢ {k}: {entity.attributes.get(k, 'N/A')}\"\n",
    "                    for k in key_attrs\n",
    "                    if k in entity.attributes\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            context_section = (\n",
    "                f\"ADDITIONAL CONTEXT:\\n{context_str}\\n\\n\" if context else \"\"\n",
    "            )\n",
    "\n",
    "            prompt = f\"\"\"You are simulating the decision-making of a specific {scenario_analysis.entity_type}.\n",
    "\n",
    "WHO YOU ARE:\n",
    "{entity.profile_summary}\n",
    "\n",
    "KEY ATTRIBUTES (most relevant for this decision):\n",
    "{key_attributes_str}\n",
    "\n",
    "SCENARIO YOU'RE FACING:\n",
    "{scenario}\n",
    "\n",
    "{context_section}AVAILABLE DECISIONS:\n",
    "{', '.join(scenario_analysis.decision_options)}\n",
    "\n",
    "TASK:\n",
    "Based on who you are, decide how you would respond to this scenario.\n",
    "\n",
    "1. decision: Choose one option from the available decisions list.\n",
    "\n",
    "2. confidence: Rate confidence 0.0-1.0. How certain are you?\n",
    "\n",
    "3. key_factor: What single attribute influenced this decision most? (max 50 words)\n",
    "\n",
    "4. trade_off: What was the main trade-off you considered? (max 50 words)\n",
    "\n",
    "5. reasoning: Optional brief explanation (1-2 sentences, max 100 words).\n",
    "\n",
    "Be concise and realistic.\"\"\"\n",
    "\n",
    "            result = await app.ai(prompt, schema=EntityDecision)\n",
    "            result.entity_id = entity.entity_id\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Failed entity {entity.entity_id}: {str(e)[:100]}\")\n",
    "            # Return a default decision instead of failing\n",
    "            return EntityDecision(\n",
    "                entity_id=entity.entity_id,\n",
    "                decision=scenario_analysis.decision_options[0]\n",
    "                if scenario_analysis.decision_options\n",
    "                else \"unknown\",\n",
    "                confidence=0.0,\n",
    "                key_factor=\"Error during decision generation\",\n",
    "                trade_off=\"Unable to evaluate\",\n",
    "                reasoning=\"Failed to generate decision\",\n",
    "            )\n",
    "\n",
    "\n",
    "# Keep old function name for backward compatibility\n",
    "async def simulate_entity_decision(\n",
    "    entity: EntityProfile,\n",
    "    scenario: str,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    context: List[str] = [],\n",
    ") -> EntityDecision:\n",
    "    \"\"\"Wrapper that uses the safe version\"\"\"\n",
    "    result = await simulate_entity_decision_safe(\n",
    "        entity, scenario, scenario_analysis, context\n",
    "    )\n",
    "    if result is None:\n",
    "        raise ValueError(f\"Failed to generate decision for {entity.entity_id}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4529cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simulate_batch_decisions(\n",
    "    entities: List[EntityProfile],\n",
    "    scenario: str,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    context: List[str] = [],\n",
    "    parallel_batch_size: int = 20,  # Reduced from 50 to avoid overload\n",
    ") -> List[EntityDecision]:\n",
    "    \"\"\"\n",
    "    üîß FIXED: Process with error handling, rate limiting, and global concurrency control.\n",
    "    - Uses return_exceptions=True to prevent one failure from killing the batch\n",
    "    - Adds delays between batches to avoid rate limits\n",
    "    - Filters out failed entities\n",
    "    - Respects global MAX_CONCURRENT_CALLS semaphore\n",
    "    \"\"\"\n",
    "    all_decisions = []\n",
    "\n",
    "    # Process in batches to control concurrency\n",
    "    num_batches = (len(entities) + parallel_batch_size - 1) // parallel_batch_size\n",
    "\n",
    "    for batch_num, i in enumerate(range(0, len(entities), parallel_batch_size)):\n",
    "        batch = entities[i : i + parallel_batch_size]\n",
    "\n",
    "        # Each entity gets its own AI call, but we do them in parallel\n",
    "        # Use return_exceptions=True so one failure doesn't kill the batch\n",
    "        tasks = [\n",
    "            simulate_entity_decision_safe(entity, scenario, scenario_analysis, context)\n",
    "            for entity in batch\n",
    "        ]\n",
    "\n",
    "        # üîß KEY FIX: Use return_exceptions=True to handle failures gracefully\n",
    "        batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        # Filter out exceptions and None values\n",
    "        valid_decisions = []\n",
    "        for result in batch_results:\n",
    "            if isinstance(result, EntityDecision):\n",
    "                valid_decisions.append(result)\n",
    "            elif isinstance(result, Exception):\n",
    "                print(f\"‚ö†Ô∏è  Exception in batch: {str(result)[:100]}\")\n",
    "            # None values are already filtered\n",
    "\n",
    "        all_decisions.extend(valid_decisions)\n",
    "\n",
    "        # Progress reporting\n",
    "        print(\n",
    "            f\"   Batch {batch_num + 1}/{num_batches}: Completed {len(all_decisions)}/{len(entities)} decisions...\"\n",
    "        )\n",
    "\n",
    "        # üîß KEY FIX: Add delay between batches to avoid rate limits\n",
    "        # Only delay if not the last batch\n",
    "        if i + parallel_batch_size < len(entities):\n",
    "            await asyncio.sleep(0.5)  # 0.5 second delay between batches\n",
    "\n",
    "    print(\n",
    "        f\"   ‚úÖ Successfully generated {len(all_decisions)}/{len(entities)} decisions\"\n",
    "    )\n",
    "    return all_decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8847eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationInsights(BaseModel):\n",
    "    \"\"\"Schema for final simulation results\"\"\"\n",
    "\n",
    "    outcome_distribution: Dict[str, float] = Field(\n",
    "        description=\"Percentage for each decision option\"\n",
    "    )\n",
    "    key_insight: str = Field(\n",
    "        description=\"One sentence summary of the most important finding\"\n",
    "    )\n",
    "    detailed_analysis: str = Field(\n",
    "        description=\"Comprehensive analysis (4-5 paragraphs) covering: overall patterns, segment differences, causal drivers, surprising findings, and implications\"\n",
    "    )\n",
    "    segment_patterns: str = Field(\n",
    "        description=\"Description of how different types of entities decided differently, organized by meaningful segments\"\n",
    "    )\n",
    "    causal_drivers: str = Field(\n",
    "        description=\"Analysis of which attributes most strongly predicted decisions, with specific examples and correlations\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def aggregate_and_analyze(\n",
    "    scenario: str,\n",
    "    scenario_analysis: ScenarioAnalysis,\n",
    "    factor_graph: FactorGraph,\n",
    "    entities: List[EntityProfile],\n",
    "    decisions: List[EntityDecision],\n",
    "    context: List[str] = [],\n",
    ") -> SimulationInsights:\n",
    "    \"\"\"\n",
    "    üîß FIXED: Only pass intelligent summaries to AI, not all raw data.\n",
    "    Pre-compute statistics, create attribute distributions, and sample representative examples.\n",
    "    \"\"\"\n",
    "    # Compute basic statistics (no AI needed)\n",
    "    total = len(decisions)\n",
    "    decision_counts = {}\n",
    "    confidence_by_decision = {}\n",
    "\n",
    "    for d in decisions:\n",
    "        decision_counts[d.decision] = decision_counts.get(d.decision, 0) + 1\n",
    "        if d.decision not in confidence_by_decision:\n",
    "            confidence_by_decision[d.decision] = []\n",
    "        confidence_by_decision[d.decision].append(d.confidence)\n",
    "\n",
    "    outcome_dist = {k: v / total for k, v in decision_counts.items()}\n",
    "    avg_confidence = {k: sum(v) / len(v) for k, v in confidence_by_decision.items()}\n",
    "\n",
    "    # üîß KEY FIX: Create intelligent summaries instead of passing all data\n",
    "\n",
    "    # 1. Attribute distribution summaries (for each attribute, show value frequencies)\n",
    "    attribute_summaries = {}\n",
    "    for attr_name in factor_graph.attributes.keys():\n",
    "        # Get all values for this attribute\n",
    "        attr_values = [\n",
    "            e.attributes.get(attr_name) for e in entities if attr_name in e.attributes\n",
    "        ]\n",
    "\n",
    "        # Count frequencies\n",
    "        value_counts = defaultdict(int)\n",
    "        for val in attr_values:\n",
    "            if val is not None:\n",
    "                # Convert to string for counting, handle different types\n",
    "                val_str = str(val)\n",
    "                value_counts[val_str] += 1\n",
    "\n",
    "        # Create summary (top 5 most common values)\n",
    "        sorted_values = sorted(value_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_values = sorted_values[:5]\n",
    "        total_with_attr = len(attr_values)\n",
    "\n",
    "        if total_with_attr > 0:\n",
    "            summary_parts = [\n",
    "                f\"{val} ({count}/{total_with_attr}, {count*100/total_with_attr:.1f}%)\"\n",
    "                for val, count in top_values\n",
    "            ]\n",
    "            attribute_summaries[attr_name] = {\n",
    "                \"distribution\": \", \".join(summary_parts),\n",
    "                \"total\": total_with_attr,\n",
    "            }\n",
    "\n",
    "    # 2. Decision patterns by attribute (which attributes correlate with which decisions)\n",
    "    decision_by_attribute = defaultdict(lambda: defaultdict(int))\n",
    "    for entity, decision in zip(entities, decisions):\n",
    "        for attr_name, attr_value in entity.attributes.items():\n",
    "            if attr_value is not None:\n",
    "                attr_str = str(attr_value)\n",
    "                decision_by_attribute[attr_name][(attr_str, decision.decision)] += 1\n",
    "\n",
    "    # Create summary of strongest correlations\n",
    "    attribute_decision_patterns = {}\n",
    "    for attr_name in factor_graph.attributes.keys():\n",
    "        if attr_name in decision_by_attribute:\n",
    "            patterns = decision_by_attribute[attr_name]\n",
    "            # Find the strongest pattern for this attribute\n",
    "            if patterns:\n",
    "                top_pattern = max(patterns.items(), key=lambda x: x[1])\n",
    "                (attr_val, decision_type), count = top_pattern\n",
    "                total_for_attr = sum(patterns.values())\n",
    "                attribute_decision_patterns[attr_name] = (\n",
    "                    f\"When {attr_name}={attr_val}: {count}/{total_for_attr} chose '{decision_type}' \"\n",
    "                    f\"({count*100/total_for_attr:.1f}%)\"\n",
    "                )\n",
    "\n",
    "    # 3. Sample representative examples intelligently\n",
    "    sample_size = min(30, len(entities))  # Max 30 examples to AI\n",
    "    samples_per_decision = max(3, sample_size // len(decision_counts))\n",
    "\n",
    "    sampled_examples = []\n",
    "    for decision_type in decision_counts.keys():\n",
    "        # Get entities that made this decision\n",
    "        matching_decisions = [d for d in decisions if d.decision == decision_type]\n",
    "        matching_entity_ids = {d.entity_id for d in matching_decisions}\n",
    "        matching_entities = {\n",
    "            e.entity_id: e for e in entities if e.entity_id in matching_entity_ids\n",
    "        }\n",
    "\n",
    "        # Sample some of them\n",
    "        sample_count = min(samples_per_decision, len(matching_entities))\n",
    "        if sample_count > 0:\n",
    "            sampled_ids = random.sample(list(matching_entities.keys()), sample_count)\n",
    "\n",
    "            for entity_id in sampled_ids:\n",
    "                entity = matching_entities[entity_id]\n",
    "                decision = next(\n",
    "                    d for d in matching_decisions if d.entity_id == entity_id\n",
    "                )\n",
    "                sampled_examples.append(\n",
    "                    {\n",
    "                        \"attributes\": entity.attributes,\n",
    "                        \"decision\": decision.decision,\n",
    "                        \"key_factor\": decision.key_factor,\n",
    "                        \"trade_off\": decision.trade_off,\n",
    "                        \"reasoning\": decision.reasoning or \"\",\n",
    "                        \"confidence\": decision.confidence,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # 4. Create segment summaries (group by common attribute combinations)\n",
    "    # Find entities with similar attribute patterns\n",
    "    segment_examples = []\n",
    "    # Group by 2-3 key attributes to create segments\n",
    "    key_attributes = list(factor_graph.attributes.keys())[:3]  # Top 3 attributes\n",
    "\n",
    "    if key_attributes:\n",
    "        segment_groups = defaultdict(list)\n",
    "        for entity, decision in zip(entities, decisions):\n",
    "            # Create a segment key from top attributes\n",
    "            segment_key = tuple(\n",
    "                str(entity.attributes.get(attr, \"unknown\")) for attr in key_attributes\n",
    "            )\n",
    "            segment_groups[segment_key].append((entity, decision))\n",
    "\n",
    "        # Get one example from each major segment\n",
    "        for segment_key, group in list(segment_groups.items())[:10]:  # Top 10 segments\n",
    "            if group:\n",
    "                entity, decision = group[0]\n",
    "                segment_examples.append(\n",
    "                    {\n",
    "                        \"segment\": f\"{', '.join(f'{k}={v}' for k, v in zip(key_attributes, segment_key))}\",\n",
    "                        \"count\": len(group),\n",
    "                        \"example_decision\": decision.decision,\n",
    "                        \"example_attributes\": entity.attributes,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Prepare context\n",
    "    context_str = \"\\n\".join([f\"- {c}\" for c in context]) if context else \"\"\n",
    "\n",
    "    # üîß Send intelligent summaries, not raw data!\n",
    "    attribute_summaries_str = json.dumps(attribute_summaries, indent=2)\n",
    "    attribute_patterns_str = \"\\n\".join(\n",
    "        [f\"  ‚Ä¢ {k}: {v}\" for k, v in list(attribute_decision_patterns.items())[:10]]\n",
    "    )\n",
    "    segment_summaries_str = json.dumps(segment_examples, indent=2)\n",
    "    sampled_examples_str = json.dumps(sampled_examples, indent=2)\n",
    "\n",
    "    if context:\n",
    "        context_block = \"CONTEXT:\\n\" + context_str + \"\\n\\n\"\n",
    "    else:\n",
    "        context_block = \"\"\n",
    "\n",
    "    prompt = f\"\"\"Analyze simulation results from {total} {scenario_analysis.entity_type} entities.\n",
    "\n",
    "SCENARIO:\n",
    "{scenario}\n",
    "\n",
    "{context_block}ATTRIBUTES TRACKED:\n",
    "{', '.join(factor_graph.attributes.keys())}\n",
    "\n",
    "OUTCOME DISTRIBUTION (from {total} entities):\n",
    "{json.dumps(outcome_dist, indent=2)}\n",
    "\n",
    "AVERAGE CONFIDENCE BY DECISION:\n",
    "{json.dumps(avg_confidence, indent=2)}\n",
    "\n",
    "ATTRIBUTE DISTRIBUTIONS (summary of value frequencies):\n",
    "{attribute_summaries_str}\n",
    "\n",
    "STRONGEST ATTRIBUTE-DECISION PATTERNS:\n",
    "{attribute_patterns_str}\n",
    "\n",
    "SEGMENT SUMMARIES (grouped by key attributes):\n",
    "{segment_summaries_str}\n",
    "\n",
    "REPRESENTATIVE EXAMPLES ({len(sampled_examples)} of {total} entities):\n",
    "{sampled_examples_str}\n",
    "\n",
    "TASK:\n",
    "Analyze these results and provide insights:\n",
    "\n",
    "1. outcome_distribution: Return this exact dictionary: {outcome_dist}\n",
    "\n",
    "2. key_insight: ONE sentence capturing the most important finding.\n",
    "\n",
    "3. detailed_analysis: 4-5 paragraphs covering:\n",
    "   - Overall pattern and dominant outcome\n",
    "   - Distinct segments and their behaviors\n",
    "   - Key drivers (which attributes predicted decisions)\n",
    "   - Surprising or counterintuitive findings\n",
    "   - Implications and recommendations\n",
    "\n",
    "4. segment_patterns: 2-3 paragraphs analyzing how different entity types decided:\n",
    "   - Group entities by meaningful attribute combinations\n",
    "   - Describe each segment's typical decision and why\n",
    "   - Note certainty levels by segment\n",
    "   - Identify interesting edge cases\n",
    "\n",
    "5. causal_drivers: 2-3 paragraphs on attribute influence:\n",
    "   - Which attributes most strongly influenced decisions\n",
    "   - Specific examples from the data\n",
    "   - Interaction effects between attributes\n",
    "   - Rank drivers by importance\n",
    "\n",
    "Be specific and reference the summarized data provided.\"\"\"\n",
    "\n",
    "    async with concurrency_semaphore:  # Global concurrency control\n",
    "        result = await app.ai(prompt, schema=SimulationInsights)\n",
    "\n",
    "    # Override with our precise computed values\n",
    "    result.outcome_distribution = outcome_dist\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f949e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN ORCHESTRATOR (FIXED FOR SCALABILITY üîß)\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "async def run_simulation(\n",
    "    scenario: str,\n",
    "    population_size: int,\n",
    "    context: List[str] = [],\n",
    "    parallel_batch_size: int = 20,  # Reduced to avoid overload (respects global MAX_CONCURRENT_CALLS)\n",
    "    exploration_ratio: float = 0.1,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    üîß FIXED: Scalable orchestrator with proper batching at each phase.\n",
    "\n",
    "    Handles large N by:\n",
    "    1. Generating entities in optimized batches (5 per AI call)\n",
    "    2. Simulating decisions in parallel batches (50 concurrent)\n",
    "    3. Sampling data for analysis (max 30 examples to AI)\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Starting simulation: {population_size} entities\")\n",
    "\n",
    "    # Phase 1: Understand scenario (single call, always fast)\n",
    "    print(\"\\nüìã Phase 1: Analyzing scenario...\")\n",
    "    scenario_analysis = await decompose_scenario(scenario, context)\n",
    "    print(f\"   Entity type: {scenario_analysis.entity_type}\")\n",
    "    print(f\"   Decision type: {scenario_analysis.decision_type}\")\n",
    "    print(f\"   Options: {scenario_analysis.decision_options}\")\n",
    "\n",
    "    # Phase 2: Build factor graph (single call, always fast)\n",
    "    print(\"\\nüï∏Ô∏è  Phase 2: Building factor graph...\")\n",
    "    factor_graph = await generate_factor_graph(scenario, scenario_analysis, context)\n",
    "    print(f\"   Tracking {len(factor_graph.attributes)} attributes\")\n",
    "\n",
    "    # Phase 3: Generate entities in optimized batches\n",
    "    print(f\"\\nüë• Phase 3: Generating {population_size} entities...\")\n",
    "\n",
    "    # üîß Generate in smart batches (5 entities per AI call, parallelize calls)\n",
    "    entities_per_batch = (\n",
    "        100  # Process 100 entities at a time (20 parallel AI calls of 5 each)\n",
    "    )\n",
    "    all_entities = []\n",
    "\n",
    "    num_batches = (population_size + entities_per_batch - 1) // entities_per_batch\n",
    "    for batch_num in range(num_batches):\n",
    "        start_id = batch_num * entities_per_batch\n",
    "        batch_size = min(entities_per_batch, population_size - start_id)\n",
    "\n",
    "        print(\n",
    "            f\"   Batch {batch_num + 1}/{num_batches}: Generating {batch_size} entities...\"\n",
    "        )\n",
    "        entities = await generate_entity_batch_optimized(\n",
    "            start_id, batch_size, scenario_analysis, factor_graph, exploration_ratio\n",
    "        )\n",
    "        all_entities.extend(entities)\n",
    "\n",
    "    print(f\"   ‚úÖ Generated {len(all_entities)} entities\")\n",
    "\n",
    "    # Phase 4: Simulate decisions in controlled parallel batches\n",
    "    print(\"\\nüéØ Phase 4: Simulating decisions...\")\n",
    "    all_decisions = await simulate_batch_decisions(\n",
    "        all_entities,\n",
    "        scenario,\n",
    "        scenario_analysis,\n",
    "        context,\n",
    "        parallel_batch_size=parallel_batch_size,\n",
    "    )\n",
    "\n",
    "    print(f\"   ‚úÖ Simulated {len(all_decisions)} decisions\")\n",
    "\n",
    "    # Phase 5: Aggregate with sampled data\n",
    "    print(\"\\nüìä Phase 5: Aggregating results and generating insights...\")\n",
    "    insights = await aggregate_and_analyze(\n",
    "        scenario, scenario_analysis, factor_graph, all_entities, all_decisions, context\n",
    "    )\n",
    "\n",
    "    print(\"\\n‚ú® Simulation complete!\")\n",
    "    print(f\"\\nüéØ KEY INSIGHT: {insights.key_insight}\")\n",
    "    print(\"\\nüìà OUTCOME DISTRIBUTION:\")\n",
    "    for decision, pct in insights.outcome_distribution.items():\n",
    "        print(f\"   {decision}: {pct*100:.1f}%\")\n",
    "\n",
    "    return {\n",
    "        \"scenario\": scenario,\n",
    "        \"context\": context,\n",
    "        \"population_size\": population_size,\n",
    "        \"scenario_analysis\": scenario_analysis,\n",
    "        \"factor_graph\": factor_graph,\n",
    "        \"entities\": all_entities,\n",
    "        \"decisions\": all_decisions,\n",
    "        \"insights\": insights,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a62ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"\"\"\n",
    "Our SaaS product currently has a free tier that 50% of our users are on.\n",
    "We're considering removing the free tier and offering a $29/month starter plan instead.\n",
    "How will existing free users react?\n",
    "\"\"\"\n",
    "\n",
    "context = [\n",
    "    \"Average free user has been with us 8 months\",\n",
    "    \"Current paid conversion rate from free is 3%\",\n",
    "    \"Two main competitors (CompetitorA and CompetitorB) offer free tiers\",\n",
    "    \"Our product is primarily used by small businesses and freelancers\",\n",
    "]\n",
    "\n",
    "# üîß Now scalable to large N!\n",
    "# Uncomment to run full simulation:\n",
    "# result = await run_simulation(\n",
    "#     scenario=scenario,\n",
    "#     population_size=5000,  # Can handle thousands!\n",
    "#     context=context,\n",
    "#     parallel_batch_size=50,  # Control concurrency\n",
    "#     exploration_ratio=0.1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a014a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Decompose the scenario\n",
    "scenario_analysis = await decompose_scenario(scenario, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fcac0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario Analysis:\n",
      "Entity Type: customer\n",
      "Decision Type: multi_option\n",
      "Decision Options: ['Convert to $29/month paid plan', 'Downgrade usage or stop using entirely', \"Switch to CompetitorA's free tier\", \"Switch to CompetitorB's free tier\", 'Seek an alternative free solution not mentioned', 'Attempt to negotiate or seek a discount']\n",
      "\n",
      "Analysis:\n",
      "The primary decision for free users revolves around perceived value and alternatives when faced with a new paywall. Key factors include the economic sensitivity of small businesses and freelancers, the perceived utility of the product, and the availability of competitors' free tiers. Causal relationships exist where longer tenure increases perceived value and switching costs, while higher dependence on the product for daily operations reduces price sensitivity. Psychological dynamics include loss aversion (reacting more strongly to losing free access) and the endowment effect (valuing something more because they already have it). Economic factors include budget constraints and the cost-benefit analysis of paying $29/month versus switching. Different segments likely exist: power users who derive high value and may convert, marginal users who use the product infrequently and will leave, and price-sensitive freelancers who will actively seek alternatives. Hidden variables include the quality of competitors' products, the ease of data migration, and potential negative word-of-mouth effects impacting brand reputation and future acquisition.\n"
     ]
    }
   ],
   "source": [
    "# Display the scenario analysis\n",
    "print(\"Scenario Analysis:\")\n",
    "print(f\"Entity Type: {scenario_analysis.entity_type}\")\n",
    "print(f\"Decision Type: {scenario_analysis.decision_type}\")\n",
    "print(f\"Decision Options: {scenario_analysis.decision_options}\")\n",
    "print(f\"\\nAnalysis:\\n{scenario_analysis.analysis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6012a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate factor graph\n",
    "factor_graph = await generate_factor_graph(scenario, scenario_analysis, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ee0910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor Graph Attributes:\n",
      "{\n",
      "  \"age\": \"Age of the primary user/decision-maker for the business\",\n",
      "  \"business_size\": \"Number of employees in the user's business (e.g., '1' for freelancer, '2-10' for small team)\",\n",
      "  \"business_revenue\": \"Annual revenue of the user's business, a proxy for budget\",\n",
      "  \"tenure_months\": \"Number of months the user has been a customer\",\n",
      "  \"usage_frequency\": \"How often the user actively uses the product (e.g., 'daily', 'weekly', 'monthly')\",\n",
      "  \"feature_dependency\": \"Extent to which the user relies on specific, high-value features unavailable in free competitors' tiers\",\n",
      "  \"perceived_value\": \"User's subjective assessment of the product's worth to their business operations\",\n",
      "  \"price_sensitivity\": \"Degree to which the user's decision is influenced by cost changes\",\n",
      "  \"loyalty_sentiment\": \"Affective attachment to the brand, measured by willingness to recommend\",\n",
      "  \"awareness_of_alternatives\": \"User's knowledge of competitor offerings (CompetitorA, CompetitorB, others)\",\n",
      "  \"switching_costs_perceived\": \"User's perceived effort, time, and risk involved in migrating to a competitor\",\n",
      "  \"dependence_on_product_for_operations\": \"How critical the product is to the user's core business workflow\",\n",
      "  \"freelancer_status\": \"Boolean indicating if the user is a freelancer or sole proprietor\",\n",
      "  \"income_level\": \"Personal income level of the primary user, if relevant for freelancers/solo users\",\n",
      "  \"location\": \"Geographic location, which may influence competitor availability and pricing perceptions\",\n",
      "  \"decision_attitude\": \"Pre-disposition towards the change (e.g., 'accepting', 'resistant', 'exploratory')\"\n",
      "}\n",
      "\n",
      "Attribute Graph:\n",
      "The attribute graph reveals interconnected pathways influencing the decision. Demographic attributes like business_size and freelancer_status create foundational context; freelancers often have tighter budgets (correlated with high_price_sensitivity). business_revenue conditions the income_level, which directly influences price_sensitivity. Usage behavior (usage_frequency, feature_dependency) is heavily influenced by tenure (a behavioral attribute), creating a causal chain: longer tenure leads to higher usage, which builds dependency, which increases perceived_value. Perceived_value is a central mediator, directly shaping decision_attitude; high value reduces switching intent. Conversely, high_price_sensitivity and awareness_of_alternatives (a contextual attribute) directly increase the likelihood of exploring competitors. Key interactions exist: price_sensitivity's effect is amplified for entities with low perceived_value or high awareness_of_alternatives. Strong predictors are perceived_value, price_sensitivity, and dependence_on_product_for_operations. Weaker predictors include age and location, though location might weakly correlate with awareness of region-specific competitors. Attributes naturally cluster: 'Power Users' (high tenure, frequency, dependency, value), 'Marginal Users' (low frequency, value, high price sensitivity), and 'Price-Sensitive Explorers' (high price sensitivity, high awareness of alternatives, freelancer status).\n",
      "\n",
      "Sampling Strategy:\n",
      "Sampling must create realistic correlation structures. business_size should be heavily skewed towards '1' (freelancers) and '2-10'. freelancer_status should be strongly correlated with business_size='1' and often with lower business_revenue and higher price_sensitivity. tenure_months should follow a distribution centered around 8 months (the average) but with a long tail. usage_frequency should be correlated with tenure_months and feature_dependency; high tenure should increase the probability of daily usage. perceived_value should be positively correlated with tenure_months, usage_frequency, and feature_dependency. price_sensitivity should be negatively correlated with business_revenue and income_level, and positively correlated with freelancer_status. awareness_of_alternatives should be moderately high overall given the competitive context. Natural archetypes to ensure representation: 1) The Power User: high tenure, daily usage, high feature dependency, high perceived value, lower price sensitivity. 2) The Marginal User: low usage frequency, short tenure, low perceived value, high price sensitivity. 3) The Cost-Conscious Freelancer: freelancer status, high price sensitivity, high awareness of alternatives. Unrealistic combinations include a freelancer with very high business_revenue, or a user with daily usage but very low perceived_value. Sampling can be done by first assigning business_size/freelancer_status, then conditioning revenue/income, then sampling tenure, and finally sampling usage behavior and attitudes conditional on these foundational attributes.\n"
     ]
    }
   ],
   "source": [
    "# Display the factor graph\n",
    "print(\"Factor Graph Attributes:\")\n",
    "print(json.dumps(factor_graph.attributes, indent=2))\n",
    "print(\"\\nAttribute Graph:\")\n",
    "print(factor_graph.attribute_graph)\n",
    "print(\"\\nSampling Strategy:\")\n",
    "print(factor_graph.sampling_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4731b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 entities\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Generate a small batch of entities (for testing)\n",
    "# Adjust batch_size as needed\n",
    "batch_size = 100\n",
    "entities = await generate_entity_batch(\n",
    "    start_id=0,\n",
    "    batch_size=batch_size,\n",
    "    scenario_analysis=scenario_analysis,\n",
    "    factor_graph=factor_graph,\n",
    "    exploration_ratio=0.1,\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(entities)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc3b0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entity:\n",
      "Entity ID: E_000000\n",
      "Profile Summary: Customer with age=29, business_size=1, business_revenue=45000, tenure_months=14, usage_frequency=daily...\n",
      "\n",
      "Attributes:\n",
      "{\n",
      "  \"age\": 29,\n",
      "  \"business_size\": \"1\",\n",
      "  \"business_revenue\": 45000,\n",
      "  \"tenure_months\": 14,\n",
      "  \"usage_frequency\": \"daily\",\n",
      "  \"feature_dependency\": \"extreme\",\n",
      "  \"perceived_value\": \"essential\",\n",
      "  \"price_sensitivity\": \"medium\",\n",
      "  \"loyalty_sentiment\": \"very_high\",\n",
      "  \"awareness_of_alternatives\": \"high\",\n",
      "  \"switching_costs_perceived\": \"very_high\",\n",
      "  \"dependence_on_product_for_operations\": \"critical\",\n",
      "  \"freelancer_status\": true,\n",
      "  \"income_level\": \"medium\",\n",
      "  \"location\": \"Portland, OR\",\n",
      "  \"decision_attitude\": \"accepting\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display a sample entity to inspect\n",
    "print(\"Sample Entity:\")\n",
    "sample_entity = entities[0]\n",
    "print(f\"Entity ID: {sample_entity.entity_id}\")\n",
    "print(f\"Profile Summary: {sample_entity.profile_summary}\")\n",
    "print(\"\\nAttributes:\")\n",
    "print(json.dumps(sample_entity.attributes, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55ad1848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 1/5: Completed 20/100 decisions...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000032: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000020: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000022: 'Exception' object has no attribute 'request'\n",
      "   Batch 2/5: Completed 40/100 decisions...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000047: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000043: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000055: 'Exception' object has no attribute 'request'\n",
      "   Batch 3/5: Completed 60/100 decisions...\n",
      "   Batch 4/5: Completed 80/100 decisions...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000081: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000080: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000086: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000088: 'Exception' object has no attribute 'request'\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "‚ö†Ô∏è  Failed entity E_000094: 'Exception' object has no attribute 'request'\n",
      "   Batch 5/5: Completed 100/100 decisions...\n",
      "   ‚úÖ Successfully generated 100/100 decisions\n",
      "Simulated 100 decisions\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Simulate decisions for all entities\n",
    "decisions = await simulate_batch_decisions(\n",
    "    entities=entities,\n",
    "    scenario=scenario,\n",
    "    scenario_analysis=scenario_analysis,\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "print(f\"Simulated {len(decisions)} decisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff43a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Decision:\n",
      "Entity ID: E_000000\n",
      "Decision: Switch to CompetitorA's free tier\n",
      "Confidence: 0.7\n",
      "Reasoning: As a price-sensitive small business owner, a new $29/month charge is significant. Since I use the product daily but know free options exist, switching is the most logical financial move.\n"
     ]
    }
   ],
   "source": [
    "# Display a sample decision to inspect\n",
    "print(\"Sample Decision:\")\n",
    "sample_decision = decisions[0]\n",
    "print(f\"Entity ID: {sample_decision.entity_id}\")\n",
    "print(f\"Decision: {sample_decision.decision}\")\n",
    "print(f\"Confidence: {sample_decision.confidence}\")\n",
    "print(f\"Reasoning: {sample_decision.reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "305d5531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Distribution:\n",
      "  Switch to CompetitorA's free tier: 49 (49.0%)\n",
      "  Convert to $29/month paid plan: 33 (33.0%)\n",
      "  Seek an alternative free solution not mentioned: 4 (4.0%)\n",
      "  Attempt to negotiate or seek a discount: 7 (7.0%)\n",
      "  Switch to CompetitorB's free tier: 7 (7.0%)\n"
     ]
    }
   ],
   "source": [
    "# Quick summary of decisions\n",
    "decision_counts = {}\n",
    "for d in decisions:\n",
    "    decision_counts[d.decision] = decision_counts.get(d.decision, 0) + 1\n",
    "\n",
    "print(\"Decision Distribution:\")\n",
    "for decision, count in decision_counts.items():\n",
    "    percentage = (count / len(decisions)) * 100\n",
    "    print(f\"  {decision}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7134247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Aggregate and analyze results\n",
    "insights = await aggregate_and_analyze(\n",
    "    scenario=scenario,\n",
    "    scenario_analysis=scenario_analysis,\n",
    "    factor_graph=factor_graph,\n",
    "    entities=entities,\n",
    "    decisions=decisions,\n",
    "    context=context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb8b0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KEY INSIGHT:\n",
      "============================================================\n",
      "Nearly half of free users will immediately defect to a known competitor's free tier upon removal of the free plan, but a core third who perceive high value will convert to paid, highlighting a sharp divide driven by price sensitivity and awareness of alternatives.\n",
      "\n",
      "============================================================\n",
      "OUTCOME DISTRIBUTION:\n",
      "============================================================\n",
      "  Switch to CompetitorA's free tier: 49.0%\n",
      "  Convert to $29/month paid plan: 33.0%\n",
      "  Seek an alternative free solution not mentioned: 4.0%\n",
      "  Attempt to negotiate or seek a discount: 7.0%\n",
      "  Switch to CompetitorB's free tier: 7.0%\n",
      "\n",
      "============================================================\n",
      "DETAILED ANALYSIS:\n",
      "============================================================\n",
      "The overall pattern reveals a clear bifurcation in user response, with 49% opting to switch to CompetitorA's free tier and 33% converting to the paid plan, indicating that the user base is sharply divided between cost-sensitive defectors and value-perceiving retainers. This split highlights the significant risk of removing the free tier, as nearly half the user base has immediate, known free alternatives, but also a substantial core sees enough value to pay. The dominant outcome of switching to a competitor underscores the critical role of competitive free offerings in the market dynamics.\n",
      "\n",
      "Distinct user segments emerge primarily along the lines of awareness and value perception. The largest segment consists of users with high awareness of CompetitorA and high price sensitivity, who defect with high confidence (0.83). Conversely, the converting segment is characterized by high perceived value and lower price sensitivity, often coupled with longer tenure and higher business revenue, demonstrating that financial stability and product integration foster willingness to pay. A smaller but notable segment of negotiators exhibits moderate price sensitivity and high feature dependency, attempting to leverage their usage into a discount rather than immediately leaving.\n",
      "\n",
      "Key drivers of the decision were overwhelmingly awareness_of_alternatives and price_sensitivity, which acted as primary gates. Users who knew about CompetitorA's free tier almost universally chose it, making market knowledge a stronger predictor than tenure or usage frequency. Surprisingly, perceived_value was a more powerful conversion driver than dependence_on_product_for_operations; some users for whom the product was critical still defected if their perceived value was low, indicating that operational necessity does not automatically translate to monetary value.\n",
      "\n",
      "A counterintuitive finding was the low confidence (0.51) among converters compared to the high confidence of defectors, suggesting that even users who choose to pay are uncertain about the decision, potentially due to the sudden nature of the change or perceived fairness. This uncertainty presents a retention risk even among paying customers. Additionally, the low rate of seeking unknown alternatives (4%) indicates that most users act on known options rather than exploring, emphasizing the importance of competitive positioning.\n",
      "\n",
      "The implications are significant: removing the free tier will likely cause substantial churn but can successfully monetize a valuable segment. Recommendations include a phased communication strategy to soften the blow, potentially offering grandfathered discounts to high-value users with low confidence, and a competitive analysis to understand why CompetitorA is so appealing. Furthermore, initiatives to increase perceived value before the change could shift more users from the defector segment to the converter segment.\n",
      "\n",
      "============================================================\n",
      "SEGMENT PATTERNS:\n",
      "============================================================\n",
      "The user base segments into three primary groups based on attribute combinations. The 'Cost-Conscious Defector' segment, characterized by high price sensitivity, high awareness of CompetitorA, and often shorter tenure or lower perceived value, overwhelmingly chose to switch to CompetitorA. This segment, representing nearly half the users, acted with high certainty (0.83 confidence) as the decision was a straightforward substitution to maintain free access. They are typically freelancers or very small businesses with lower revenue for whom the $29 cost is a significant barrier.\n",
      "\n",
      "The 'Value-Driven Converter' segment is defined by high perceived value, lower price sensitivity, and longer tenure. These users, often from slightly larger businesses (2-10 employees) with higher revenue, decided to convert to the paid plan. Interestingly, their confidence was the lowest of all groups (0.51), indicating internal conflict despite their choice; they value the product but are uneasy about the forced monetization. A subset of this segment, those with very high dependence on the product for operations, converted with higher confidence, showing that necessity can override price concerns.\n",
      "\n",
      "A smaller but strategic segment is the 'Negotiator,' typically users with medium price sensitivity, high feature dependency, and an 'exploratory' decision attitude. This group did not immediately defect or convert but attempted to negotiate, suggesting they see enough value to stay but hope for a better deal. Their moderate confidence (0.65) reflects a wait-and-see approach. An edge case is users with high business revenue but low perceived value who still defected, showing that absolute affordability is less important than subjective value judgment in the decision calculus.\n",
      "\n",
      "============================================================\n",
      "CAUSAL DRIVERS:\n",
      "============================================================\n",
      "The most decisive factor was awareness_of_alternatives, where 'high' awareness consistently led to switching to CompetitorA, creating a clear link between market knowledge and churn. Perceived_value was a strong predictor for conversion, with entities rating it 'high' being three times more likely to convert to paid than those with 'low' perceived value, as high value justifies the new cost. Price_sensitivity directly suppressed conversion; those with 'high' sensitivity overwhelmingly chose free alternatives, while those with 'low' sensitivity were the primary converter segment. An important interaction was high dependence_on_product_for_operations combined with high loyalty_sentiment; when both were present, conversion likelihood doubled, but if loyalty was low, even critical dependence users sought free alternatives. The driver importance ranking is: 1) awareness_of_alternatives, 2) price_sensitivity, 3) perceived_value, 4) loyalty_sentiment, 5) dependence_on_product_for_operations.\n"
     ]
    }
   ],
   "source": [
    "# Display the insights\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 60)\n",
    "print(insights.key_insight)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTCOME DISTRIBUTION:\")\n",
    "print(\"=\" * 60)\n",
    "for decision, pct in insights.outcome_distribution.items():\n",
    "    print(f\"  {decision}: {pct*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED ANALYSIS:\")\n",
    "print(\"=\" * 60)\n",
    "print(insights.detailed_analysis)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SEGMENT PATTERNS:\")\n",
    "print(\"=\" * 60)\n",
    "print(insights.segment_patterns)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CAUSAL DRIVERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(insights.causal_drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e43cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
